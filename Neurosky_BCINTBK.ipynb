{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Abstract"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "report findings and contributions "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motivations\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The inital underpinnings of our research is to create a remote and non-invasive EEG program that allows the reading of neural activity, predominantly in the FP1 electrode placement seen in the 10-20 electrode placement system and a base electrode that serves as an average of neural activity clipped onto the ear (A1,10-20 system), that projects actions onto an affordable visual headset, in this case we decided to utilize a Oculus Quest (2?).The gathered neural activity of the NeuroSky includes a concentration gradient, calm gradient, attentuation state and blinking detection that allows for a varied amount of input and information of the subject in hand (BCIs should be constructed as a way to put the subject first as invasive and non-invasive BCIs put the individual at risk due to malfunction, code bugs, and unprecedented obstables that can cause a disabled individual from recovering of such an action, such as a fall) that allows for projection of intention without any physical attribution. Such endogenous cuing should have a direct correlation to an action in any digital space, since it is the easiest way to replicate environments for a person to persist in with actions beyond physically capable. Even though the NeuroSky has limited reading potentials, this gives light to the idea of non-invasive alternatives for those needing extra assistance or that with an electrode cap system, there could be a finer reading of neural activity that can be associated with a certain system of interaction, such as a digital display. The preclaimed Oculus Quest(2?) has a sensor that provides en-vivo capture of the surrounding area similar to the testla lidar system that also allows for the visual aspect of this (research?) experiment to become mobile.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Link contains a detailed description of the threshold for Neurosky comms output to laptop.\n",
    "\n",
    "Motivation for Connecting Neurosky to a Oculus Rift and Opening A Video Game/Gui with nerual activity:\n",
    "https://ieeexplore.ieee.org/document/9467310 \n",
    "\n",
    "NeuroSky Information and Applciation Link:\n",
    "https://store.neurosky.com/products/neuroexperimenter\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neurosky Applications and Methodology\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Augmented Reality Oculus Quest Implementation\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualizing Data(EDA/ Plots)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Future Endeavors and Experimental Challenges/Changes\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Robitic Implementation \n",
    "EEG controlled guidance of machines such as robitic implants that have future implications with a non-invasive BCI tailoring to avergaed EEG data through a wireless system. External control of a more complete system like a robotic machine would allow for individuals with complications to become more independent that requiring help from other people.\n",
    "\n",
    "## Augmented Reality Lab Work\n",
    "As seen with the ability for the oculus quest virtual environment to excite the FP1 lobe for concentration, calm and blinking readings, there is a way to measure salient information through the scope of augmented reality. With a virutal environment \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
